"""
CNN Classifier for EuroSAT or general 32Ã—32 RGB image classification.

- 3Ã— Conv + BatchNorm + ReLU + MaxPool êµ¬ì¡°
- Fully Connected classifier block
- hidden_dims, dropout ë¹„ìœ¨ ë“±ì„ ì„¤ì •ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥
- TrainerTorch(trainer_torch.py)ì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ êµ¬ì¡°
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import List, Optional

import torch
import torch.nn as nn

# ---------------------------------------------------------------------------
# ğŸ”µ CNN ì„¤ì •ê°’
# ---------------------------------------------------------------------------


@dataclass
class CNNConfig:
    """
    CNN ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° êµ¬ì„±.

    Attributes:
        num_classes (int): ìµœì¢… ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜.
        channels (List[int]): ê° Conv ë¸”ë¡ì˜ output channel ìˆ˜.
        dropout (float): fc layer dropout ë¹„ìœ¨.
        use_batchnorm (bool): BatchNorm ì‚¬ìš© ì—¬ë¶€.
    """

    num_classes: int = 10
    channels: List[int] = None
    dropout: float = 0.3
    use_batchnorm: bool = True


# ---------------------------------------------------------------------------
# ğŸ”µ CNN Classifier
# ---------------------------------------------------------------------------


class CNNClassifier(nn.Module):
    """
    32Ã—32 RGB ì…ë ¥ìš© CNN ê¸°ë°˜ ë¶„ë¥˜ê¸°.

    êµ¬ì¡°:
        Conv1 â†’ BN â†’ ReLU â†’ MaxPool
        Conv2 â†’ BN â†’ ReLU â†’ MaxPool
        Conv3 â†’ BN â†’ ReLU â†’ MaxPool
        â†’ Flatten â†’ FC â†’ ReLU â†’ Dropout â†’ FC(num_classes)

    Conv ì„¤ì •ì€ CNNConfig.channels ë¡œ ì¡°ì • (ì˜ˆ: [32, 64, 128])
    """

    def __init__(self, config: Optional[CNNConfig] = None):
        super().__init__()

        if config is None:
            config = CNNConfig(channels=[32, 64, 128])

        self.config = config

        chs = config.channels
        if chs is None or len(chs) < 1:
            raise ValueError("CNNConfig.channels ëŠ” ìµœì†Œ 1ê°œ ì´ìƒì˜ ì±„ë„ ìˆ˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")

        layers: List[nn.Module] = []
        in_c = 3  # ì…ë ¥ ì´ë¯¸ì§€ RGB 3ì±„ë„

        # Conv Blocks êµ¬ì„± -------------------------------------------------
        for out_c in chs:
            layers.append(nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1))
            if config.use_batchnorm:
                layers.append(nn.BatchNorm2d(out_c))
            layers.append(nn.ReLU())
            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
            in_c = out_c

        self.features = nn.Sequential(*layers)

        # ìµœì¢… feature map í¬ê¸° ê³„ì‚° ----------------------------------------
        # Conv êµ¬ì„±ì„ ë³€ê²½í•´ë„ ìë™ìœ¼ë¡œ flatten dimensionì„ ê³„ì‚°í•˜ë„ë¡ ë”ë¯¸ ì…ë ¥ì„ í†µê³¼ì‹œí‚¨ë‹¤.
        with torch.no_grad():
            dummy = torch.zeros(1, 3, 32, 32)
            fm = self.features(dummy)
            fm_size = int(fm.shape[1] * fm.shape[2] * fm.shape[3])

        # Classifier block ---------------------------------------------------
        self.classifier = nn.Sequential(
            nn.Linear(fm_size, 256),
            nn.ReLU(),
            nn.Dropout(config.dropout),
            nn.Linear(256, config.num_classes),
        )

    # ----------------------------------------------------------------------
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward ê³„ì‚°.

        Args:
            x (Tensor): (B, 3, 32, 32) ì…ë ¥ ì´ë¯¸ì§€

        Returns:
            Tensor: (B, num_classes) ë¡œì§“(logit)
        """
        out = self.features(x)  # (B, C3, 4, 4)
        out = torch.flatten(out, 1)  # (B, C3*4*4)
        out = self.classifier(out)  # (B, num_classes)
        return out

    # ----------------------------------------------------------------------
    def count_parameters(self) -> int:
        """
        í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ë°˜í™˜.

        Returns:
            int: íŒŒë¼ë¯¸í„° ê°œìˆ˜
        """
        return sum(p.numel() for p in self.parameters() if p.requires_grad)
