"""
ë”¥ëŸ¬ë‹ ëª¨ë¸(Multi-Layer Perceptron / CNN ë“±)ì„ í•™ìŠµí•  ë•Œ í•„ìš”í•œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ìŒ.

ì£¼ìš” ê¸°ëŠ¥:
    - ì‹¤í–‰ ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ(CUDA â†’ MPS â†’ CPU)
    - ëœë¤ ì‹œë“œ ê³ ì •(seed_everything)
    - ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°(count_parameters)
    - DataLoader worker ì´ˆê¸°í™”(worker_init_fn)
    - ëª¨ë¸ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±(model_summary)
"""

from __future__ import annotations

import os
import random
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from model.dl.cnn import CNNClassifier, CNNConfig
from model.dl.convnext import ConvNeXtClassifier, ConvNeXtConfig
from model.dl.mlp import MLPClassifier, MLPConfig
from model.dl.resnet import ResNetClassifier, ResNetConfig

# ---------------------------------------------------------------------------
# ğŸ”µ Device ì„ íƒ
# ---------------------------------------------------------------------------


def get_device() -> torch.device:
    """
    ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ device(CUDA â†’ MPS â†’ CPU)ë¥¼ ìë™ ì„ íƒí•œë‹¤.

    Returns:
        torch.device: cuda, mps, cpu ì¤‘ í•˜ë‚˜
    """
    if torch.cuda.is_available():
        return torch.device("cuda")
    if torch.backends.mps.is_available():
        return torch.device("mps")
    return torch.device("cpu")


# ---------------------------------------------------------------------------
# ğŸ”µ Random Seed ê³ ì •
# ---------------------------------------------------------------------------


def seed_everything(seed: int = 2025) -> None:
    """
    Python, NumPy, PyTorchì˜ ëœë¤ ì‹œë“œë¥¼ ëª¨ë‘ ê³ ì •í•œë‹¤.

    Args:
        seed (int): ì‹œë“œ ê°’

    Notes:
        reproducibilityë¥¼ ë†’ì´ê¸° ìœ„í•´ cudnn deterministic ì˜µì…˜ì„ í™œì„±í™”í•˜ì§€ë§Œ,
        ì„±ëŠ¥ì´ ì¡°ê¸ˆ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ.
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


# ---------------------------------------------------------------------------
# ğŸ”µ DataLoader Worker Seed ì„¤ì •
# ---------------------------------------------------------------------------


def worker_init_fn(worker_id: int) -> None:
    """
    DataLoaderì˜ workerë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥¸ ì‹œë“œë¥¼ ì ìš©í•œë‹¤.

    Args:
        worker_id (int): worker ID
    """
    seed = np.random.get_state()[1][0] + worker_id
    np.random.seed(seed)
    random.seed(seed)


# ---------------------------------------------------------------------------
# ğŸ”µ ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°œìˆ˜
# ---------------------------------------------------------------------------


def count_parameters(model: nn.Module) -> int:
    """
    í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë°˜í™˜í•œë‹¤.

    Args:
        model (nn.Module): PyTorch ëª¨ë¸

    Returns:
        int: trainable parameters ê°œìˆ˜
    """
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


# ---------------------------------------------------------------------------
# ğŸ”µ ëª¨ë¸ summary (torchsummary ì—†ì´ ì§ì ‘ êµ¬í˜„)
# ---------------------------------------------------------------------------


def model_summary(model: nn.Module, input_size: Tuple[int, ...]) -> str:
    """
    torchsummary ì—†ì´ ì§ì ‘ êµ¬í˜„í•œ ê°„ë‹¨í•œ ëª¨ë¸ ìš”ì•½(summary).

    Args:
        model (nn.Module): PyTorch ëª¨ë¸
        input_size (Tuple[int, ...]): ì…ë ¥ í…ì„œ í¬ê¸° (ì˜ˆ: (3, 32, 32))

    Returns:
        str: summary ë¬¸ìì—´
    """
    device = get_device()
    dummy = torch.zeros((1, *input_size)).to(device)

    summary_lines: List[str] = []
    summary_lines.append("=== Model Summary ===")

    def forward_hook(module, inp, out):
        class_name = module.__class__.__name__
        in_shape = tuple(inp[0].size())
        out_shape = tuple(out.size()) if isinstance(out, torch.Tensor) else "various"

        params = sum(p.numel() for p in module.parameters() if p.requires_grad)
        summary_lines.append(f"{class_name:20s} | Input: {in_shape} -> Output: {out_shape} | Params: {params}")

    hooks = []
    for layer in model.modules():
        # ì²« ë²ˆì§¸ ëª¨ë“ˆ(model ìì²´)ì€ skip
        if layer is model:
            continue
        hooks.append(layer.register_forward_hook(forward_hook))

    # Forward ì‹¤í–‰
    _ = model(dummy)

    # hook ì œê±°
    for h in hooks:
        h.remove()

    total_params = count_parameters(model)
    summary_lines.append(f"\nTotal Trainable Params: {total_params:,}")

    return "\n".join(summary_lines)


# ---------------------------------------------------------------------------
# ğŸ”µ DataLoader ì „ì²´ ë¼ë²¨ ìˆ˜ì§‘
# ---------------------------------------------------------------------------


def collect_loader_targets(loader: DataLoader) -> np.ndarray:
    """DataLoaderì˜ ëª¨ë“  ë°°ì¹˜ ë¼ë²¨ì„ numpy ë°°ì—´ë¡œ ì´ì–´ ë¶™ì¸ë‹¤.

    Args:
        loader (DataLoader): ë¼ë²¨ì„ ìˆ˜ì§‘í•  PyTorch DataLoader.

    Returns:
        np.ndarray: í•©ì³ì§„ ë¼ë²¨ ë²¡í„°(int64).
    """
    labels: List[int] = []
    for _, y in loader:
        labels.extend(np.asarray(y, dtype=np.int64).tolist())
    return np.asarray(labels, dtype=np.int64)


# ---------------------------------------------------------------------------
# ğŸ”µ ëª¨ë¸ ë¹Œë” (HW scripts ê³µìœ )
# ---------------------------------------------------------------------------

DEFAULT_DL_CONFIGS: Dict[str, Dict[str, Any]] = {
    "mlp": {
        "hidden": [512, 256],
        "dropout": 0.3,
    },
    "cnn": {
        "channels": [32, 64, 128],
        "dropout": 0.3,
        "use_batchnorm": True,
    },
    "resnet": {
        "layers": (2, 2, 2),
        "base_channels": 32,
    },
    "convnext": {
        "depths": (2, 2, 2),
        "dims": (64, 128, 256),
    },
}


def build_dl_model(model_type: str, num_classes: int, params: Optional[Dict[str, Any]] = None) -> nn.Module:
    """EuroSAT ë¶„ë¥˜ìš© DL ëª¨ë¸ì„ ìƒì„±í•œë‹¤.

    Args:
        model_type (str): {"mlp", "cnn", "resnet", "convnext"} ì¤‘ ì„ íƒ.
        num_classes (int): ë¶„ë¥˜ í´ë˜ìŠ¤ ê°œìˆ˜.
        params (Optional[Dict[str, Any]]): Hyperopt ê²°ê³¼ ë“±ìœ¼ë¡œë¶€í„° ì½ì€ íŒŒë¼ë¯¸í„° dict.

    Returns:
        nn.Module: ìƒì„±ëœ PyTorch ë¶„ë¥˜ ëª¨ë¸.

    Raises:
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” model_typeì¼ ê²½ìš°.
    """
    if model_type not in DEFAULT_DL_CONFIGS:
        raise ValueError(f"Unsupported DL model type: {model_type}")

    params = params or {}
    defaults = DEFAULT_DL_CONFIGS[model_type]

    # Set Random Seed
    seed_everything(2025)

    # Define model
    if model_type == "mlp":
        cfg = MLPConfig(
            input_dim=32 * 32 * 3,
            num_classes=num_classes,
            hidden_dims=params.get("hidden", defaults["hidden"]),
            dropout=float(params.get("dropout", defaults["dropout"])),
        )
        return MLPClassifier(cfg)

    if model_type == "cnn":
        cfg = CNNConfig(
            num_classes=num_classes,
            channels=params.get("channels", defaults["channels"]),
            dropout=float(params.get("dropout", defaults["dropout"])),
            use_batchnorm=bool(params.get("use_batchnorm", defaults["use_batchnorm"])),
        )
        return CNNClassifier(cfg)

    if model_type == "resnet":
        cfg = ResNetConfig(
            num_classes=num_classes,
            layers=tuple(params.get("layers", defaults["layers"])),
            base_channels=int(params.get("base_channels", defaults["base_channels"])),
        )
        return ResNetClassifier(cfg)

    cfg = ConvNeXtConfig(
        num_classes=num_classes,
        depths=tuple(params.get("depths", defaults["depths"])),
        dims=tuple(params.get("dims", defaults["dims"])),
    )
    return ConvNeXtClassifier(cfg)
